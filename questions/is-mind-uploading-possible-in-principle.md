---
question: Is mind uploading possible in principle?
position: No
inspiration: https://www.reddit.com/r/artificial/s/35sttrXqb0
elaboration: Is it possible, if only in principle, to scan a human brain and relocate its mental activity to a digital computer such that the conscious mind once “in” the brain is instead “in” the computer?
published: true
---
## The core matter
This seems like a straightforward question about the nature of consciousness but I don’t think we need to know anything about consciousness specifically to answer this question. Nothing, that is, beyond the premise that consciousness is a physical phenomenon and nothing else like spirit stuff. There wouldn’t be much reason to engage with this question after all if one were not a physicalist. 

While mind uploading could only be possible if digital minds are possible that is a distinct question: [Are digital minds possible in principle?](/questions/are-digital-minds-possible-in-principle) The question at hand extends the topic and introduces the additional concern of “uploading” particular minds typically with an implicit interest in preservation. It’s this aspect of the question that allows for the possibility of diverging answers. What this question additionally depends upon is the nature of identity. Nothing about the possibility of digital minds determines the identity of a particular mind.
## Equivalency and identity  
Even though the typical person engaged with this question is a physicalist, dualistic intuitions about the nature of mind are still quite common, and I suspect that they underly the motivation for this question. These intuitions, it seems to me, are ironically evoked by a functional analysis that characterizes mental activity as abstract processes that can be realized by any system capable of performing those functions. Once one thinks about thoughts as floating free of a particular physical substrate, similar to a dualist, the relocation of those thoughts seems like an actual possibility. While this is a relevant matter for, again, the question of [digital minds](/questions/are-digital-minds-possible-in-principle) here it can’t help as it only changes the topic from the core matter of identity to the topic of sufficiency. 
### Twins
Consider two identical twins. Could their similarities, no matter how exact, ever be sufficient for establishing a single identity? Even if they were atom-for-atom identical they would remain two distinct people. And even if we reduced their personhood to thought-for-thought duplicates of each other so that whenever one had a thought the other had the same thought such that there was no sense of psychological identity to distinguish the two, they would remain two distinct physical objects in the world. The answer to this question hinges on this distinction. 
### Identity and being identical
It is common for people to speak loosely of two or more things being identical to each other when they look similar. But in philosophy and logic, “identity” has a far more strict sense. For two physical objects to truly be identical they would have all of the same properties including a location in space. Even when two objects have all of the same properties (and this is never really the case when we look closer) they have distinct locations in space and distinct histories in time  making them distinct objects. This is the sense of  “identical” that matters here. When it comes to being something, like being you right now, something or someone else being a lot like you in some ways just doesn’t matter to your being identical to yourself (which all things are). 
### Mental identity 
If psychological identity were reducible to functional sufficiency then such twins would be psychologically identical even while being physically distinct. But in conjunction with the premise of physicalism, this would be a contradiction. From a purely physical perspective, if the two twins have all of the same thoughts, their brain states are nonetheless distinct physical states. So to accept a single mental identity one would have to slip into dualistic thinking and see the physical states as irrelevant to the identity of the thoughts. But for the physicalist, the mental is physical so this can’t be correct.

This is why I take it that mind uploading is not possible in principle. Even if  a perfect duplicate of your mind were created in a computer as a result of some physical scan and subsequent simulation of your brain’s structure and activity, it wouldn’t relocate you. If minds are physical, then mental identity just is physical identity. Duplicating mental activity would create a unique physical identity no matter how similar the resulting mind is. Functional similarity just isn’t physical identity and if minds are physical then mental identity just is physical identity. Intuition and logic seem to be in harmony. Only once one begins preferring functional similarity over physical identity does one begin to think otherwise. But if one rejects dualism, then this is a mistake.
## Philosophy vs. science fiction
Here is how a mind uploading scenario would play out in our world. You would wake up in a dumpster groggy, confused and surrounded by corpses. Something went wrong, you would think, and you would be right. The mechanism that was intended to kill you after the brain scan malfunctioned. At the same moment, another person would think that it had worked just as they expected, but they would be wrong, of course, because they never expected anything. They didn’t even exist before this moment. They would be a functional duplicate of you and since duplicates of anything are never physically identical with what they are duplicates of they are not you. They are most certainly like you—perhaps in almost all of the meaningful ways—but that surprising degree of similarity doesn’t change the fact that they are living in the digital paradise that you paid for while you are in a dumpster groggy, confused, and surrounded by corpses. 